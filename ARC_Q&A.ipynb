{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9gZKXfajIuH"
   },
   "source": [
    "#### 0. Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wph_j13QjES0"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPEI677Z1wCK"
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "while(1):\n",
    "    a.append('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tnlGJ19jel8"
   },
   "source": [
    "#### 1. Install the necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "9IEIY43kjT8M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\aviparna.biswas\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\aviparna.biswas\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\aviparna.biswas\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\aviparna.biswas\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet transformers\n",
    "!pip install --quiet pytorch-lightning\n",
    "!pip install --quiet tokenizers\n",
    "!pip install --quiet sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "e-HjDksaj6EY"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "B5J5tgMJj6sC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from termcolor import colored\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "qRL5NBT6j_b_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "KybRFE8wkEik"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "O0nXACNukHuV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBgu8GX0kMiX"
   },
   "source": [
    "#### 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2120,
     "status": "ok",
     "timestamp": 1650616225081,
     "user": {
      "displayName": "Aviparna Biswas",
      "userId": "09264704011974348727"
     },
     "user_tz": -330
    },
    "id": "RPzbBRBFY7Bh",
    "outputId": "fdb75c1c-ac12-4360-db7f-5231b93a6e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1C-MJgB8kRb97NK97hyn4LFhuTZE4aFdw\n",
      "To: /content/ARC.zip\n",
      "100% 2.02k/2.02k [00:00<00:00, 2.87MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1C-MJgB8kRb97NK97hyn4LFhuTZE4aFdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcmzTqJYote8"
   },
   "outputs": [],
   "source": [
    "!unzip -q ARC.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "GLEqLr6lkKNu"
   },
   "outputs": [],
   "source": [
    "with Path(\"ARC/arc-train-factoid-1c.json\").open(encoding = \"utf-8\") as json_file:\n",
    "  data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "deQiuW7Jldta"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'version'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "_dk_QLwKlgSh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARC_Q&A'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"version\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "-AwMsvZHljD2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paragraphs', 'title'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"data\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "rnGxK6yFloHE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARC_Q&A'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"data\"][0][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "XpUrzi65lrNN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'qas': [{'id': 'ARC_QUE_063',\n",
       "    'question': 'Was the Aspire opened on the correct mortgage account?',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'},\n",
       " {'qas': [{'id': 'ARC_QUE_064',\n",
       "    'question': 'Was the Aspire opened on an M&amp;T Serviced Loan, M&amp;T returned check, and/or Insurance check?',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'},\n",
       " {'qas': [{'id': 'ARC_QUE_065',\n",
       "    'question': 'Was the Aspire opened to the correct team?',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'},\n",
       " {'qas': [{'id': 'ARC_QUE_066',\n",
       "    'question': 'Was the check copy and / or documentation attached to the Aspire?',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'},\n",
       " {'qas': [{'id': 'ARC_QUE_067',\n",
       "    'question': 'If instructions were given outside the Aspire Case, was documentation attached evidencing the instructions? (Internal Chat, Email, ETC.)',\n",
       "    'answers': [{'text': 'Not Applicable', 'answer_start': 11}]}],\n",
       "  'context': 'Yes 1 No 0 Not Applicable 1'},\n",
       " {'qas': [{'id': 'ARC_QUE_068',\n",
       "    'question': 'If an Aspire request could not be completed, was a valid explanation provided which follows M&amp;T payment posting policy and procedures?',\n",
       "    'answers': [{'text': 'Not Applicable', 'answer_start': 11}]}],\n",
       "  'context': 'Yes 1 No 0 Not Applicable 1'},\n",
       " {'qas': [{'id': 'ARC_QUE_069',\n",
       "    'question': 'Select Aspire Results',\n",
       "    'answers': [{'text': 'Applied per Instructions', 'answer_start': 0}]}],\n",
       "  'context': 'Applied per Instructions 1 Refund Checks 1 3rd Party Funds/Short Sales 1 Reinstatements 1 Returned Checks 1 Credited or Debited to DDA or GL/CC 1'},\n",
       " {'qas': [{'id': 'ARC_QUE_070',\n",
       "    'question': 'Were funds applied per the instructions provided?',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'},\n",
       " {'qas': [{'id': 'ARC_QUE_071',\n",
       "    'question': 'Were funds applied using the correct effective date? (MSP – P309/S3; Effective date for all funds should mirror Aspire Case “Check RCVD Date”)',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'},\n",
       " {'qas': [{'id': 'ARC_QUE_072',\n",
       "    'question': 'Were all actions taken on or by the Aspire Completion Date?',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'},\n",
       " {'qas': [{'id': 'ARC_QUE_073',\n",
       "    'question': 'Was the Aspire noted with GL/CC number or DDA account?',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'},\n",
       " {'qas': [{'id': 'ARC_QUE_074',\n",
       "    'question': 'Was the correct action taken and M&amp;T guidelines followed?',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'},\n",
       " {'qas': [{'id': 'ARC_QUE_075',\n",
       "    'question': 'Were all the actions taken on or by Aspire Completion Date?',\n",
       "    'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       "  'context': 'Yes 1 No 0'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"data\"][0][\"paragraphs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "BpvjOKkOx2On"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"data\"][0][\"paragraphs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "GLPGwXPUmkMe"
   },
   "outputs": [],
   "source": [
    "questions = data[\"data\"][0][\"paragraphs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "B5u5Y6Lnmmrt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qas': [{'id': 'ARC_QUE_063',\n",
       "   'question': 'Was the Aspire opened on the correct mortgage account?',\n",
       "   'answers': [{'text': 'Yes', 'answer_start': 0}]}],\n",
       " 'context': 'Yes 1 No 0'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnlVxJq1mtj8"
   },
   "source": [
    "#### 3. Defining our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "8q5EhAHHmpAg"
   },
   "outputs": [],
   "source": [
    "def extract_questions_and_answers(factoid_path: Path):\n",
    "    with factoid_path.open() as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    questions = data[\"data\"][0][\"paragraphs\"]\n",
    "\n",
    "    data_rows = []\n",
    "\n",
    "    for question in questions:\n",
    "        context = question[\"context\"]\n",
    "        for question_and_answers in question[\"qas\"]:\n",
    "            question = question_and_answers[\"question\"]\n",
    "            answers = question_and_answers[\"answers\"]\n",
    "\n",
    "            for answer in answers:\n",
    "                answer_text = answer[\"text\"]\n",
    "                answer_start = answer[\"answer_start\"]\n",
    "                answer_end = answer_start + len(answer_text)\n",
    "\n",
    "                data_rows.append({\n",
    "                    \"question\":question,\n",
    "                    \"context\":context,\n",
    "                    \"answer_text\":answer_text,\n",
    "                    \"answer_start\":answer_start,\n",
    "                    \"answer_end\":answer_end\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Zyq_8eMzm6tA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did the LO brand PHH Mortgage?</td>\n",
       "      <td>PASS/ 1 FAIL/0 NA/0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did the LO identify themselves by First and La...</td>\n",
       "      <td>PASS/ 1 FAIL/0 NA/0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did the LO give the customer their NMLS ID #?</td>\n",
       "      <td>PASS/ 1 FAIL/0 NA/0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did the LO state the following: 'This call is ...</td>\n",
       "      <td>PASS/ 1 FAIL/0 NA/0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did the LO obtain last 4 of SSN and property a...</td>\n",
       "      <td>PASS/ 1 FAIL/0 NA/0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question              context  \\\n",
       "0                     Did the LO brand PHH Mortgage?  PASS/ 1 FAIL/0 NA/0   \n",
       "1  Did the LO identify themselves by First and La...  PASS/ 1 FAIL/0 NA/0   \n",
       "2      Did the LO give the customer their NMLS ID #?  PASS/ 1 FAIL/0 NA/0   \n",
       "3  Did the LO state the following: 'This call is ...  PASS/ 1 FAIL/0 NA/0   \n",
       "4  Did the LO obtain last 4 of SSN and property a...  PASS/ 1 FAIL/0 NA/0   \n",
       "\n",
       "  answer_text  answer_start  answer_end  \n",
       "0        PASS             0           4  \n",
       "1        PASS             0           4  \n",
       "2        PASS             0           4  \n",
       "3        PASS             0           4  \n",
       "4        PASS             0           4  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_questions_and_answers(Path(\"ARC/arc-train-factoid-1a.json\")).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "6hkXQEvEoFi-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('ARC/arc-train-factoid-1a.json'),\n",
       " WindowsPath('ARC/arc-train-factoid-1b.json'),\n",
       " WindowsPath('ARC/arc-train-factoid-1c.json')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factoid_paths = sorted(list(Path(\"ARC/\").glob(\"arc-train-*\")))\n",
    "factoid_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "-Zm5BAZ_p3YI"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 6504: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-113477ce339f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfactoid_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfactoid_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_questions_and_answers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactoid_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-67214dcc8f26>\u001b[0m in \u001b[0;36mextract_questions_and_answers\u001b[1;34m(factoid_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_questions_and_answers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactoid_path\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfactoid_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mquestions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"paragraphs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m     return loads(fp.read(),\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 6504: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for factoid_path in factoid_paths:\n",
    "    dfs.append(extract_questions_and_answers(factoid_path))\n",
    "\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XRHydEmOp8iA"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcfwQzn2qAMw"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLBSU1vzqFKw"
   },
   "outputs": [],
   "source": [
    "len(df.question.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUd4MaoRqID-"
   },
   "outputs": [],
   "source": [
    "len(df.context.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOKVQUbTqLAx"
   },
   "outputs": [],
   "source": [
    "sample_question = df.iloc[21]\n",
    "sample_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gCI5arcqVhd"
   },
   "outputs": [],
   "source": [
    "def color_answer(question):\n",
    "  answer_start, answer_end = question[\"answer_start\"], question[\"answer_end\"]\n",
    "  context = question[\"context\"]\n",
    "\n",
    "  return colored(context[:answer_start], \"red\") + \\\n",
    "    colored(context[answer_start:answer_end + 1], \"green\") + \\\n",
    "    colored(context[answer_end + 1:], \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mT12ZtiIqbu-"
   },
   "outputs": [],
   "source": [
    "print(sample_question[\"question\"])\n",
    "print()\n",
    "print(\"Answer:\")\n",
    "\n",
    "for wrap in textwrap.wrap(color_answer(sample_question), width=120):\n",
    "  print(wrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRTWTJW1q6je"
   },
   "source": [
    "#### 5. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hhw5TPjbqhel"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 't5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0Ksjor-rAdw"
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMeO6hRWrCqQ"
   },
   "outputs": [],
   "source": [
    "encoding = tokenizer(\n",
    "    sample_question[\"question\"],\n",
    "    sample_question[\"context\"],\n",
    "    max_length=396,\n",
    "    padding=\"max_length\",\n",
    "    truncation=\"only_second\",\n",
    "    return_attention_mask = True,\n",
    "    add_special_tokens = True,\n",
    "    return_tensors = \"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlwkYI6srGn4"
   },
   "outputs": [],
   "source": [
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWi-a7pZrKSI"
   },
   "outputs": [],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgp6_rMbrMzg"
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zKJRSAmrVqB"
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(encoding[\"input_ids\"].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEy4zk0mrY9W"
   },
   "outputs": [],
   "source": [
    "answer_encoding = tokenizer(\n",
    "    sample_question[\"answer_text\"],\n",
    "    max_length=32,\n",
    "    padding = \"max_length\",\n",
    "    truncation = True,\n",
    "    return_attention_mask = True,\n",
    "    add_special_tokens = True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7p-xGQQrfdp"
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(answer_encoding[\"input_ids\"].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IXo6DceriCH"
   },
   "outputs": [],
   "source": [
    "labels = answer_encoding[\"input_ids\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCGE8al4rmQX"
   },
   "outputs": [],
   "source": [
    "labels[labels ==0] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0Q_hpjIrpxS"
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ei6UNKXTrsHT"
   },
   "outputs": [],
   "source": [
    "class ARCQADataset(Dataset):\n",
    "\n",
    "  def __init__(\n",
    "    self, \n",
    "    data: pd.DataFrame,\n",
    "    tokenizer: T5Tokenizer,\n",
    "    source_max_token_len: int = 396,\n",
    "    target_max_token_len: int = 32  \n",
    "  ):\n",
    "\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data = data\n",
    "    self.source_max_token_len = source_max_token_len\n",
    "    self.target_max_token_len = target_max_token_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index:int):\n",
    "    data_row = self.data.iloc[index]\n",
    "\n",
    "    source_encoding = tokenizer(\n",
    "        data_row[\"question\"],\n",
    "        data_row[\"context\"],\n",
    "        max_length=self.source_max_token_len,\n",
    "        padding=\"max_length\",\n",
    "        truncation=\"only_second\",\n",
    "        return_attention_mask = True,\n",
    "        add_special_tokens = True,\n",
    "        return_tensors = \"pt\"\n",
    "    )\n",
    "\n",
    "    target_encoding = tokenizer(\n",
    "        sample_question[\"question\"],\n",
    "        sample_question[\"context\"],\n",
    "        max_length=self.source_max_token_len,\n",
    "        padding=\"max_length\",\n",
    "        truncation=\"only_second\",\n",
    "        return_attention_mask = True,\n",
    "        add_special_tokens = True,\n",
    "        return_tensors = \"pt\"\n",
    "    )\n",
    "\n",
    "    labels = target_encoding[\"input_ids\"]\n",
    "    labels[labels==0] = -100\n",
    "\n",
    "    return dict(\n",
    "        question = data_row[\"question\"],\n",
    "        context = data_row[\"context\"],\n",
    "        answer_text = data_row[\"answer_text\"],\n",
    "        input_ids = source_encoding[\"input_ids\"].flatten(),\n",
    "        attention_mask = source_encoding[\"attention_mask\"].flatten(),\n",
    "        labels = labels.flatten()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwVNRrsDr8AU"
   },
   "outputs": [],
   "source": [
    "sample_dataset = ARCQADataset(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tgKie9PsBeK"
   },
   "outputs": [],
   "source": [
    "for data in sample_dataset:\n",
    "  print(data[\"question\"])\n",
    "  print(data[\"answer_text\"])\n",
    "  print(data[\"input_ids\"][:10])\n",
    "  print(data[\"labels\"][:10])\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snmiGp8SsJTh"
   },
   "source": [
    "#### 6. Train and Validate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Av4eBV2HsEmZ"
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fK1Z12IJsP-c"
   },
   "outputs": [],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9DtMdXtsS1M"
   },
   "outputs": [],
   "source": [
    "class ARCQADataModule(pl.LightningDataModule):\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      train_df: pd.DataFrame,\n",
    "      test_df: pd.DataFrame,\n",
    "      tokenizer: T5Tokenizer,\n",
    "      batch_size: int = 8,\n",
    "      source_max_token_len = 396,\n",
    "      target_max_token_len = 32\n",
    "    ):\n",
    "      super().__init__()\n",
    "      self.batch_size = batch_size\n",
    "      self.train_df = train_df\n",
    "      self.test_df = test_df\n",
    "      self.tokenizer = tokenizer\n",
    "      self.source_max_token_len = source_max_token_len\n",
    "      self.target_max_token_len = target_max_token_len\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    self.train_dataset = ARCQADataset(\n",
    "        self.train_df,\n",
    "        self.tokenizer,\n",
    "        self.source_max_token_len,\n",
    "        self.target_max_token_len\n",
    "    )\n",
    "\n",
    "    self.test_dataset = ARCQADataset(\n",
    "        self.test_df,\n",
    "        self.tokenizer,\n",
    "        self.source_max_token_len,\n",
    "        self.target_max_token_len\n",
    "    )\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(\n",
    "        self.train_dataset,\n",
    "        batch_size = self.batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = 4\n",
    "    )\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(\n",
    "        self.train_dataset,\n",
    "        batch_size = 1,\n",
    "        shuffle = True,\n",
    "        num_workers = 4  \n",
    "    )\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(\n",
    "        self.train_dataset,\n",
    "        batch_size = 1,\n",
    "        shuffle = True,\n",
    "        num_workers = 4  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YrMAmfZsrmB"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "N_EPOCHS = 6\n",
    "\n",
    "data_module = ARCQADataModule(train_df, val_df, tokenizer, batch_size = BATCH_SIZE)\n",
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIE_wSVfsw8X"
   },
   "outputs": [],
   "source": [
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u613Mg8ks3Hl"
   },
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxmmphPOs6C7"
   },
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1G23PMr0tHGW"
   },
   "outputs": [],
   "source": [
    "output = model(\n",
    "    input_ids = encoding[\"input_ids\"],\n",
    "    attention_mask = encoding[\"attention_mask\"],\n",
    "    labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNBHfneZtNeL"
   },
   "outputs": [],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TP3-bkeTtQof"
   },
   "outputs": [],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHFnR6b8tZi_"
   },
   "source": [
    "#### 7. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHXZHrv4tTCM"
   },
   "outputs": [],
   "source": [
    "class ARCQAModel(pl.LightningModule):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels=None):\n",
    "    output = self.model(\n",
    "        input_ids = encoding[\"input_ids\"],\n",
    "        attention_mask = encoding[\"attention_mask\"],\n",
    "        labels=labels\n",
    "    )\n",
    "\n",
    "    return output.loss, output.logits\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss \n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return AdamW(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQ8dlAO5xpQO"
   },
   "outputs": [],
   "source": [
    "model = ARCQAModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfST-_IVxvYJ"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ek7Y77nHxzcf"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath = \"checkpoints\",\n",
    "    filename = \"best-checkpoint\",\n",
    "    save_top_k = 1,\n",
    "    verbose = True,\n",
    "    monitor = \"val_loss\",\n",
    "    mode = \"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mf3--_1Sx2Ki"
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs= N_EPOCHS,\n",
    "    #gpus=1,\n",
    "    progress_bar_refresh_rate=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdTvKcXEx5yQ"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQIK3REm5sls"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WJEVOP44clK"
   },
   "outputs": [],
   "source": [
    "!rm -rf lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkcM2jq1yBCz"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jKRCX1pyH33"
   },
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKnvs1-H817s"
   },
   "source": [
    "#### 8. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g2xlYEg8egT"
   },
   "outputs": [],
   "source": [
    "trained_model = ARCQAModel.load_from_checkpoint(\"checkpoints/best-checkpoint.ckpt\")\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9bg9c0e9ljy"
   },
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "  source_encoding = tokenizer(\n",
    "      question[\"question\"],\n",
    "      question[\"context\"],\n",
    "      max_length = 396,\n",
    "      padding=\"max_length\",\n",
    "      truncation = \"only_second\",\n",
    "      return_attention_mask = True,\n",
    "      add_special_tokens = True,\n",
    "      return_tensors = \"pt\"\n",
    "  )\n",
    "\n",
    "  generated_ids = trained_model.model.generate(\n",
    "      input_ids = source_encoding[\"input_ids\"],\n",
    "      attention_mask = source_encoding[\"attention_mask\"],\n",
    "      num_beams = 1,\n",
    "      max_length = 80,\n",
    "      repetition_penalty = 2.5,\n",
    "      length_penalty = 1.0,\n",
    "      early_stopping = True,\n",
    "      use_cache = True\n",
    "  )\n",
    "\n",
    "  preds = [\n",
    "      tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "      for generated_id in generated_ids\n",
    "  ]\n",
    "\n",
    "  return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmYl2B9q96UD"
   },
   "outputs": [],
   "source": [
    "sample_question = val_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSth5WiT97g5"
   },
   "outputs": [],
   "source": [
    "sample_question[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5wUCLnx_6eQ"
   },
   "outputs": [],
   "source": [
    "sample_question[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGHwqH6PAAuu"
   },
   "outputs": [],
   "source": [
    "generate_answer(sample_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUsgYHVbAK_B"
   },
   "outputs": [],
   "source": [
    "sample_question = val_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDG1o7KHAc0n"
   },
   "outputs": [],
   "source": [
    "sample_question[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lh2Z9cNuAe3w"
   },
   "outputs": [],
   "source": [
    "sample_question[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNHbZd2XAhPm"
   },
   "outputs": [],
   "source": [
    "generate_answer(sample_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYkQVFUOAk8w"
   },
   "outputs": [],
   "source": [
    "sample_question = train_df.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbT0fR2bI-Eb"
   },
   "outputs": [],
   "source": [
    "sample_question[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "am5DLTxvJEKj"
   },
   "outputs": [],
   "source": [
    "sample_question[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKhTJL4iJFzc"
   },
   "outputs": [],
   "source": [
    "sample_question = train_df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77C8tv2-NIbA"
   },
   "outputs": [],
   "source": [
    "sample_question[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUi09IlCNKM4"
   },
   "outputs": [],
   "source": [
    "sample_question[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tkjDpzmNRmh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyMZiSzKngtOw4R6WZPGJOeH",
   "collapsed_sections": [
    "mnlVxJq1mtj8",
    "iRTWTJW1q6je",
    "snmiGp8SsJTh",
    "DHFnR6b8tZi_",
    "tKnvs1-H817s"
   ],
   "name": "ARC_Q&A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
